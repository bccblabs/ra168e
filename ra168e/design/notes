
spiders
=======================================
scraping cycle
    1. 
        - generate initial requests to cral first urls, and specify a callback with response from requests
        - first requests obtained from start_requests()
        - start_request generate Request from urls from start_urls
        - parse() -> callback function
    2.  - parse response and return Item, or Request Objects, or iterable of both
    3.  - callback functions parse the response with Selectors, generate items from parsed data
    4.  - Item pipeline handles exporting


start_urls
    - list of url to begin crawl from, subsequent urls generated successively from data from these URLs

start_requests()
    - return an iterable with the first Requests to crawl for this spider
    - called when no particular urls are specified, otherwise, make_requests_from_url() is called
    - called once from Scrapy
    - default: call make_requests_from_url() for each in start_urls

make_requests_from_url(url)
    - receives a URL and returns a request object or a list of Request objects
    - used for constructing the initial requests in the start_requests() method
    - used for converting urls to requests
    - returns Requests with the parse() method as callback as default

link extractors
=========================================
xpath
    - language for selecting nodes in xml docs 

css
    - defines selector to associate styles with html elements
