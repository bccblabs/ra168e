2015-10-09 02:22:43 [scrapy] INFO: Scrapy 1.0.3.post1+g83a06ed started (bot: ra168e)
2015-10-09 02:22:43 [scrapy] INFO: Optional features available: ssl, http11
2015-10-09 02:22:43 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'ra168e.spiders', 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS': 3, 'SPIDER_MODULES': ['ra168e.spiders'], 'BOT_NAME': 'ra168e', 'LOG_FILE': 'pure_images.log', 'DOWNLOAD_DELAY': 1}
2015-10-09 02:22:43 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-10-09 02:22:43 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-10-09 02:22:43 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-10-09 02:22:45 [py.warnings] WARNING: /usr/local/lib/python2.7/dist-packages/scrapy_mongodb.py:30: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2015-10-09 02:22:45 [py.warnings] WARNING: /usr/local/lib/python2.7/dist-packages/scrapy_mongodb.py:31: ScrapyDeprecationWarning: Module `scrapy.contrib.exporter` is deprecated, use `scrapy.exporters` instead
  from scrapy.contrib.exporter import BaseItemExporter

2015-10-09 02:22:45 [scrapy] INFO: Enabled item pipelines: DownloadClassifyPipeline, MongoDBPipeline
2015-10-09 02:22:45 [scrapy] INFO: Spider opened
2015-10-09 02:22:45 [py.warnings] WARNING: /usr/local/lib/python2.7/dist-packages/scrapy_mongodb.py:105: ScrapyDeprecationWarning: log.msg has been deprecated, create a python logger and log through it instead
  self.config['collection']))

2015-10-09 02:22:45 [scrapy] INFO: Connected to MongoDB mongodb://localhost:27017, using "pure_images4/urls"
2015-10-09 02:22:45 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-10-09 02:23:01 [scrapy] ERROR: Error processing {'bodyType': u'sedan',
 'image_urls': [],
 'keywords': [u'76,212',
              u'sedan',
              u'silver',
              u'58001025',
              u'wvwaf93dx58001025',
              u'gasoline',
              u'6-speed automatic',
              u'awd',
              u'4',
              u'4.2l v8 40v mpfi dohc'],
 'listing_id': '628903577',
 'listing_url': 'http://www.cars.com/vehicledetail/detail/628903577/overview/',
 'make': u'volkswagen',
 'model': u'phaeton v8',
 'year': u'2005'}
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/twisted/internet/defer.py", line 577, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/ra168e/ra168e/pipelines.py", line 42, in item_completed
    item['ext'] = ext_images
  File "/usr/lib/pymodules/python2.7/scrapy/item.py", line 63, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'vehicle_urls does not support field: ext'
2015-10-09 02:23:01 [scrapy] ERROR: Error processing {'bodyType': u'sedan',
 'image_urls': [],
 'keywords': [u'119,957',
              u'sedan',
              u'jasper green pearl',
              u'graphite',
              u'5b176a',
              u'2g4ws52j611100371',
              u'gasoline',
              u'4-speed automatic',
              u'fwd',
              u'4',
              u'3.1l v6 12v mpfi ohv'],
 'listing_id': '647796091',
 'listing_url': 'http://www.cars.com/vehicledetail/detail/647796091/overview/',
 'make': u'buick',
 'model': u'century custom',
 'year': u'2001'}
Traceback (most recent call last):
  File "/usr/lib/python2.7/dist-packages/twisted/internet/defer.py", line 577, in _runCallbacks
    current.result = callback(current.result, *args, **kw)
  File "/home/ubuntu/ra168e/ra168e/pipelines.py", line 42, in item_completed
    item['ext'] = ext_images
  File "/usr/lib/pymodules/python2.7/scrapy/item.py", line 63, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'vehicle_urls does not support field: ext'
2015-10-09 02:23:22 [scrapy] INFO: Received SIGINT, shutting down gracefully. Send again to force 
2015-10-09 02:23:24 [scrapy] INFO: Received SIGINT twice, forcing unclean shutdown
2015-10-09 02:24:56 [scrapy] INFO: Scrapy 1.0.3.post1+g83a06ed started (bot: ra168e)
2015-10-09 02:24:56 [scrapy] INFO: Optional features available: ssl, http11
2015-10-09 02:24:56 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'ra168e.spiders', 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS': 3, 'SPIDER_MODULES': ['ra168e.spiders'], 'BOT_NAME': 'ra168e', 'LOG_FILE': 'pure_images.log', 'DOWNLOAD_DELAY': 1}
2015-10-09 02:24:56 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-10-09 02:24:56 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-10-09 02:24:56 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-10-09 02:24:56 [py.warnings] WARNING: /usr/local/lib/python2.7/dist-packages/scrapy_mongodb.py:30: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2015-10-09 02:24:56 [py.warnings] WARNING: /usr/local/lib/python2.7/dist-packages/scrapy_mongodb.py:31: ScrapyDeprecationWarning: Module `scrapy.contrib.exporter` is deprecated, use `scrapy.exporters` instead
  from scrapy.contrib.exporter import BaseItemExporter

2015-10-09 02:24:56 [scrapy] INFO: Enabled item pipelines: DownloadClassifyPipeline, MongoDBPipeline
2015-10-09 02:24:56 [scrapy] INFO: Spider opened
2015-10-09 02:24:56 [py.warnings] WARNING: /usr/local/lib/python2.7/dist-packages/scrapy_mongodb.py:105: ScrapyDeprecationWarning: log.msg has been deprecated, create a python logger and log through it instead
  self.config['collection']))

2015-10-09 02:24:56 [scrapy] INFO: Connected to MongoDB mongodb://localhost:27017, using "pure_images4/urls"
2015-10-09 02:24:56 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-10-09 02:25:56 [scrapy] INFO: Crawled 29 pages (at 29 pages/min), scraped 9 items (at 9 items/min)
2015-10-09 02:26:04 [py.warnings] WARNING: /usr/local/lib/python2.7/dist-packages/scrapy_mongodb.py:256: ScrapyDeprecationWarning: log.msg has been deprecated, create a python logger and log through it instead
  spider=spider)

2015-10-09 02:26:56 [scrapy] INFO: Crawled 58 pages (at 29 pages/min), scraped 18 items (at 9 items/min)
2015-10-09 02:27:05 [py.warnings] WARNING: /usr/local/lib/python2.7/dist-packages/scrapy_mongodb.py:258: ScrapyDeprecationWarning: log.msg has been deprecated, create a python logger and log through it instead
  log.msg(u'Duplicate key found', level=log.DEBUG)

2015-10-09 02:27:21 [scrapy] INFO: Received SIGTERM, shutting down gracefully. Send again to force 
2015-10-09 02:27:21 [scrapy] INFO: Closing spider (shutdown)
2015-10-09 02:27:23 [scrapy] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 167153,
 'downloader/request_count': 120,
 'downloader/request_method_count/GET': 120,
 'downloader/response_bytes': 1485937,
 'downloader/response_count': 120,
 'downloader/response_status_count/200': 71,
 'downloader/response_status_count/301': 49,
 'dupefilter/filtered': 22,
 'finish_reason': 'shutdown',
 'finish_time': datetime.datetime(2015, 10, 9, 2, 27, 23, 197867),
 'item_scraped_count': 22,
 'log_count/INFO': 11,
 'log_count/WARNING': 5,
 'request_depth_max': 2,
 'response_received_count': 71,
 'scheduler/dequeued': 120,
 'scheduler/dequeued/memory': 120,
 'scheduler/enqueued': 308,
 'scheduler/enqueued/memory': 308,
 'start_time': datetime.datetime(2015, 10, 9, 2, 24, 56, 840241)}
2015-10-09 02:27:23 [scrapy] INFO: Spider closed (shutdown)
2015-10-09 02:34:00 [scrapy] INFO: Scrapy 1.0.3.post1+g83a06ed started (bot: ra168e)
2015-10-09 02:34:00 [scrapy] INFO: Optional features available: ssl, http11
2015-10-09 02:34:00 [scrapy] INFO: Overridden settings: {'NEWSPIDER_MODULE': 'ra168e.spiders', 'LOG_LEVEL': 'INFO', 'CONCURRENT_REQUESTS': 5, 'SPIDER_MODULES': ['ra168e.spiders'], 'BOT_NAME': 'ra168e', 'LOG_FILE': 'pure_images.log', 'DOWNLOAD_DELAY': 1}
2015-10-09 02:34:00 [scrapy] INFO: Enabled extensions: CloseSpider, TelnetConsole, LogStats, CoreStats, SpiderState
2015-10-09 02:34:00 [scrapy] INFO: Enabled downloader middlewares: HttpAuthMiddleware, DownloadTimeoutMiddleware, UserAgentMiddleware, RetryMiddleware, DefaultHeadersMiddleware, MetaRefreshMiddleware, HttpCompressionMiddleware, RedirectMiddleware, CookiesMiddleware, ChunkedTransferMiddleware, DownloaderStats
2015-10-09 02:34:00 [scrapy] INFO: Enabled spider middlewares: HttpErrorMiddleware, OffsiteMiddleware, RefererMiddleware, UrlLengthMiddleware, DepthMiddleware
2015-10-09 02:34:01 [py.warnings] WARNING: /usr/local/lib/python2.7/dist-packages/scrapy_mongodb.py:30: ScrapyDeprecationWarning: Module `scrapy.log` has been deprecated, Scrapy now relies on the builtin Python library for logging. Read the updated logging entry in the documentation to learn more.
  from scrapy import log

2015-10-09 02:34:01 [py.warnings] WARNING: /usr/local/lib/python2.7/dist-packages/scrapy_mongodb.py:31: ScrapyDeprecationWarning: Module `scrapy.contrib.exporter` is deprecated, use `scrapy.exporters` instead
  from scrapy.contrib.exporter import BaseItemExporter

2015-10-09 02:34:01 [scrapy] INFO: Enabled item pipelines: DownloadClassifyPipeline, MongoDBPipeline
2015-10-09 02:34:01 [scrapy] INFO: Spider opened
2015-10-09 02:34:01 [py.warnings] WARNING: /usr/local/lib/python2.7/dist-packages/scrapy_mongodb.py:105: ScrapyDeprecationWarning: log.msg has been deprecated, create a python logger and log through it instead
  self.config['collection']))

2015-10-09 02:34:01 [scrapy] INFO: Connected to MongoDB mongodb://localhost:27017, using "pure_images4/urls"
2015-10-09 02:34:01 [scrapy] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2015-10-09 02:35:37 [py.warnings] WARNING: /usr/local/lib/python2.7/dist-packages/scrapy_mongodb.py:256: ScrapyDeprecationWarning: log.msg has been deprecated, create a python logger and log through it instead
  spider=spider)

2015-10-09 02:35:37 [scrapy] INFO: Crawled 13 pages (at 13 pages/min), scraped 1 items (at 1 items/min)
2015-10-09 02:35:40 [py.warnings] WARNING: /usr/local/lib/python2.7/dist-packages/scrapy_mongodb.py:258: ScrapyDeprecationWarning: log.msg has been deprecated, create a python logger and log through it instead
  log.msg(u'Duplicate key found', level=log.DEBUG)

2015-10-09 02:36:01 [scrapy] INFO: Crawled 38 pages (at 25 pages/min), scraped 2 items (at 1 items/min)
2015-10-09 02:37:27 [scrapy] INFO: Received SIGTERM, shutting down gracefully. Send again to force 
2015-10-09 02:37:38 [scrapy] INFO: Received SIGTERM twice, forcing unclean shutdown
